{"cells":[{"metadata":{"_uuid":"0479e25c001874fda15f875d76f8663885caa138"},"cell_type":"markdown","source":"# Study if classes form separable clusters\nThis kernel closely follows https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro for data cleaning and feature engineering. \n\n# Short summary\nIt seems that the class 4 = _\"non vulnerable households\"_ form clusters that can be separated from the rest of the clusters. The rest of classes are all mixed together"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4e08a17549fd247619178c96c3ade2519e9773"},"cell_type":"markdown","source":"The following categorical mapping originates from [this kernel](https://www.kaggle.com/mlisovyi/categorical-variables-encoding-function)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndef encode_data(df):\n    '''\n    The function does not return, but transforms the input pd.DataFrame\n    \n    Encodes the Costa Rican Household Poverty Level data \n    following studies in https://www.kaggle.com/mlisovyi/categorical-variables-in-the-data\n    and the insight from https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#359631\n    \n    The following columns get transformed: edjefe, edjefa, dependency, idhogar\n    The user most likely will simply drop idhogar completely (after calculating houshold-level aggregates)\n    '''\n    \n    yes_no_map = {'no': 0, 'yes': 1}\n    \n    df['dependency'] = df['dependency'].replace(yes_no_map).astype(np.float32)\n    \n    df['edjefe'] = df['edjefe'].replace(yes_no_map).astype(np.float32)\n    df['edjefa'] = df['edjefa'].replace(yes_no_map).astype(np.float32)\n    \n    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1785c8ca3467a7e95d007a2c5f36e39919fc0910"},"cell_type":"markdown","source":"**There is also feature engineering magic happening here:**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"9c9f13e54fc2af9f938b895959631e1aeb3b08a2"},"cell_type":"code","source":"def do_features(df):\n    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n                 ('working_man_fraction', 'r4h2', 'r4t3'),\n                 ('all_man_fraction', 'r4h3', 'r4t3'),\n                 ('human_density', 'tamviv', 'rooms'),\n                 ('human_bed_density', 'tamviv', 'bedrooms'),\n                 ('rent_per_person', 'v2a1', 'r4t3'),\n                 ('rent_per_room', 'v2a1', 'rooms'),\n                 ('mobile_density', 'qmobilephone', 'r4t3'),\n                 ('tablet_density', 'v18q1', 'r4t3'),\n                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n                 ('tablet_adult_density', 'v18q1', 'r4t2')\n                ]\n    \n    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n                 ('people_weird_stat', 'tamhog', 'r4t3')]\n\n    for f_new, f1, f2 in feats_div:\n        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n    for f_new, f1, f2 in feats_sub:\n        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n    \n    # aggregation rules over household\n    aggs_num = {'age': ['min', 'max', 'mean', 'count'],\n                'escolari': ['min', 'max', 'mean', 'std']\n               }\n    aggs_cat = {'dis': ['mean']}\n    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n            aggs_cat[f_] = ['mean']\n    # aggregation over household\n    for name_, df_ in [('18', df.query('age >= 18'))]:\n        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n        df = df.join(df_agg, how='left', on='idhogar')\n        del df_agg\n    df.fillna(0, inplace=True)\n    # do something advanced above...\n    \n    # Drop SQB variables, as they are just squres of other vars \n    df.drop([f_ for f_ in df.columns if f_.startswith('SQB') or f_ == 'agesq'], axis=1, inplace=True)\n    # Drop id's\n    df.drop(['Id'], axis=1, inplace=True)\n    # Drop repeated columns\n    df.drop(['hhsize', 'female', 'area2'], axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab84429fc9893c82e33b8319161c190b4104e9f"},"cell_type":"markdown","source":"# Read in the data and clean it up"},{"metadata":{"trusted":true,"_uuid":"e6f696a1677230c565532f141a02852e7c69b2e1","collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\n#We do not need the test sample for this exercise\n#test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"334238c8c677787a13a08a621827c6f1b0565046","collapsed":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd1f66cbdbfa4741d19a8b1f53793b967d62d281","collapsed":true},"cell_type":"code","source":"def process_df(df_):\n    # fix categorical features\n    encode_data(df_)\n    #fill in missing values based on https://www.kaggle.com/mlisovyi/missing-values-in-the-data\n    for f_ in ['v2a1', 'v18q1', 'meaneduc', 'SQBmeaned']:\n        df_[f_] = df_[f_].fillna(0)\n    df_['rez_esc'] = df_['rez_esc'].fillna(-1)\n    # do feature engineering and drop useless columns\n    return do_features(df_)\n\ntrain = process_df(train)\n#test = process_df(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65dab0e9a94e8f87a7b73e7ec2c6559e4ccef996","scrolled":true,"collapsed":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"809763b29c54f5a15da2c5670407eaf95c62cfc2"},"cell_type":"markdown","source":"Note the change in the number of features of different type. What we did was:\n- encoded categorical variables appropreately into numerical values;\n- dropped a few irrelevant columns;\n- added several columns with household aggregates and cand-crafted ratio and subtraction features"},{"metadata":{"_uuid":"9858e0b145850825a201df702ffd1eddc4ff6eba"},"cell_type":"markdown","source":"# VERY IMPORTANT\n> Note that ONLY the heads of household are used in scoring. All household members are included in test + the sample submission, but only heads of households are scored."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96e8311b0d5cdddcf98b03d47d5e4793f0b79f03"},"cell_type":"code","source":"X = train.query('parentesco1==1')#.sample(frac=0.2)\n\n# pull out the target variable\ny = X['Target'] - 1\nX = X.drop(['Target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5eaa7e4a95326459a7f2aeb24949e45cb237a9a4","collapsed":true},"cell_type":"code","source":"cols_2_drop=[]\n\nX.drop((cols_2_drop+['idhogar']), axis=1, inplace=True)\n#test.drop((cols_2_drop+['idhogar']), axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61924fd573a74d7e8b0b1f0e66f61c92afe29f82"},"cell_type":"markdown","source":"# Scale the training data\nData data has to be rescaled to mean of 0 and variance of 1, since most of the following algorithms use distance metric. We will initialise 3 different scalers: `StandardScaler`, `RobustScaler` and `MinMaxScaler` but only one will be used later on"},{"metadata":{"trusted":true,"_uuid":"b9f71bd6f88588f9f64801bb570430a1b8f0d0ea","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e3f39318caafc874e2c2d6909a4ad94fddfe81","collapsed":true},"cell_type":"code","source":"rs = RobustScaler().fit(X)\nss = StandardScaler().fit(X)\nmm = MinMaxScaler().fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0503fb568560648186c3b838eb604e34af0085b1"},"cell_type":"code","source":"X_rs = pd.DataFrame(rs.transform(X), columns=X.columns)\nX_ss = pd.DataFrame(ss.transform(X), columns=X.columns)\nX_mm = pd.DataFrame(mm.transform(X), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8e3a9a16f30d715ecef3a6ffea7b4592d30fb20"},"cell_type":"markdown","source":"Define helper functions  `transform_data` and `plot_transformed_data` that will be used by all following clustering algorithms."},{"metadata":{"trusted":true,"_uuid":"213bff309afb610d199933a156cce08d753a2992","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"import time\nfrom sklearn.base import clone\ndef transform_data(tr_, X_, configs_, tr_name_):\n    X_tr = {}\n    for i,params in configs_.items():\n        print('---------- {} -----------'.format(params))\n        t_start = time.clock()\n        X_tr[i] = clone(tr_).set_params(**params).fit_transform(X_ss)\n        t_end = time.clock()\n        print('{} fitted in {} sec'.format(tr_name_, t_end-t_start))\n    return X_tr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2a457410fcda14041567699d009e576114e0dae6","_kg_hide-input":true},"cell_type":"code","source":"colors=['r','b','y','g']\ndef plot_transformed_data(X_tr_, y_, configs_, tr_name_):\n    for j, X_ in X_tr_.items():\n        plt.figure(figsize=(6,4))\n        for i in [3,0,1, 2]:\n            plt.scatter(X_[y_==i,0], X_[y_==i,1], c=colors[i], s=5, label=i+1)\n        plt.legend()\n        plt.title('{}: {}'.format(tr_name_, configs_[j]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6fce8205f4e5ae78a43eef4f0fd3cead5a3cb04"},"cell_type":"markdown","source":"# t-SNE\nDefine several variants to see dependence on the input parameters"},{"metadata":{"trusted":true,"_uuid":"8ff1779cb09cb3215bee9365e7f7ab899487fdcd","collapsed":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne_configs = {1: dict(init='random'),\n                2: dict(init='pca'),\n                3: dict(init='pca', n_iter=5000),\n                4: dict(init='pca', n_iter=500),\n                5: dict(init='pca', learning_rate=50),\n                6: dict(init='pca', learning_rate=500),\n                7: dict(init='pca', perplexity=15),\n                8: dict(init='pca', perplexity=50)}\nX_tsne = transform_data(TSNE(n_components=2, random_state=314), \n                        X_rs, \n                        tsne_configs, \n                        't-SNE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"66524188a08c67adc2a5fc6664c774ba6234ac38","collapsed":true},"cell_type":"code","source":"plot_transformed_data(X_tsne, y, tsne_configs, 't-SNE')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7476233fa29241b76aa4b37969e18802037287b"},"cell_type":"markdown","source":"As one can see, the green dots (class 4 = _non vulnerable households_) can be separated from the rest, while the other three classes are closely mixed together"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"581b7015bd0bd5cfa37b9e503a19b0b465750567"},"cell_type":"markdown","source":"# MDS\nDefine several variants to see dependence on the input parameters"},{"metadata":{"trusted":true,"_uuid":"466d0da24b768c4d51464f8a92a5c7292a3d522d","collapsed":true},"cell_type":"code","source":"from sklearn.manifold import MDS\n\nmds_configs = {1: dict(max_iter=100),\n               2: dict(max_iter=300),\n               3: dict(max_iter=500)}\nX_mds = transform_data(MDS(n_components=2, n_init=2, n_jobs=1, random_state=314), \n                       X_rs, \n                       mds_configs, \n                       'MDS')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cd3693d82c399151747caa6ad414bda9938d8f5","collapsed":true},"cell_type":"code","source":"plot_transformed_data(X_mds, y, mds_configs, 'MDS')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cddc526340486bfeb846a0ed362b9f152e0a9edf"},"cell_type":"markdown","source":"As one can see, the green dots (class 4 = _non vulnerable households_) can be separated from the rest (in particular, for `max_iter=500`), while the other three classes are closely mixed together"},{"metadata":{"_uuid":"0cbf1dc2c88cf2f3572d77426bd7e482def022e7"},"cell_type":"markdown","source":"# Isomap\nDefine several variants to see dependence on the input parameters"},{"metadata":{"trusted":true,"_uuid":"dd910eeb8788f1857f817e09e46bafcb95a8e64c","collapsed":true},"cell_type":"code","source":"from sklearn.manifold import Isomap\n\niso_configs = {1: dict(n_neighbors=20),\n               2: dict(n_neighbors=50),\n               3: dict(n_neighbors=100)}\nX_isomap = transform_data(Isomap(n_components=2, n_jobs=4), \n                       X_rs, \n                       iso_configs, \n                       'Isomap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67f7d894a801b0984a6d4536de6b05345b4cff74","collapsed":true},"cell_type":"code","source":"plot_transformed_data(X_isomap, y, iso_configs, 'Isomap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7c7abf336064579f95afb18c684a4b55b6c722d4"},"cell_type":"markdown","source":"As one can see, the green dots (class 4 = _non vulnerable households_) can be separated from the rest, while the other three classes are closely mixed together"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}