{"cells":[{"metadata":{"_uuid":"bfefc03e60a3399ee6aaec29ba71ec39bfbe83d3"},"cell_type":"markdown","source":"# Why this kernel?\nWhy should you read through this kernel? The goal is to implement the full chain (skipping over EDA) from data access to preparation of submission and to provide functional example of LightGBM advanced usage:\n\n- the data will be read and **memory footprint will be reduced**;\n- **missing data** will be checked;\n- _feature engineering is not implemented yet_;\n- a baseline model will be trained:\n   - Gradient boosting model as implemented in **LightGBM** is used;\n   - **Mean absolute error (MAE) is used as the loss function** in the training (consistently with the final evaluation metric). **FAIR loss**  is also tried and was found to lead similar results\n   - Training is performed with **early stopping based on MAE metric**.\n   - **Learning rate in the training is reduced (decays) from iteration to iteration** to improve convergence (one starts with high and finishes with low learning rate)\n - The training is implemented in a cross validation (CV) loop and **out-of-fold (OOF) predictions are stored** for future use in stacking.\n - **Test predictions** are obtained as an **average over predictions from models trained on k-1 fold subsets**.\n- Predictions are **clipped to `[0,1]` range**\n\nSee another my kernel showing how to significantly improve the score by using relative ranking of teams within games: \nhttps://www.kaggle.com/mlisovyi/relativerank-of-predictions"},{"metadata":{"_uuid":"73fa2d9e1fe335a7bddc673d056b0eb092c92eca"},"cell_type":"markdown","source":"# Side note: score of 0.0635 can be achieved with only 50k entries from the train set"},{"metadata":{"trusted":true,"_uuid":"de54aea187ca94ee3e3a27ebcd020cdffe855cb9"},"cell_type":"code","source":"# The number of entries to read in. Use it to have fast turn-around. The values are separate for train and test sets\nmax_events_trn=None\nmax_events_tst=None\n# Number on CV folds\nn_cv=3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8c2280c84ba4940112e24766017f2802edab801"},"cell_type":"markdown","source":"Define a function to reduce memory foorprint"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0d144d5a4de449c1d744d528d0e1d8e21ec8899e"},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        elif 'datetime' not in col_type.name:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4292e016577a9a1971be047e11c173462ee7d43c"},"cell_type":"markdown","source":"Read in the data"},{"metadata":{"trusted":true,"_uuid":"74fa1a7102ea9b9e660408f106db77db51284df5"},"cell_type":"code","source":"df_trn = pd.read_csv('../input/train.csv', nrows=max_events_trn)\ndf_trn = reduce_mem_usage(df_trn)\n\ndf_tst = pd.read_csv('../input/test.csv',  nrows=max_events_tst)\ndf_tst = reduce_mem_usage(df_tst)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5769611594f0be21b35805fbee239cc9dc72a577"},"cell_type":"markdown","source":"## How do the data look like?"},{"metadata":{"trusted":true,"_uuid":"5b34b961208d6d98839eadd4ac38c9041c70713c"},"cell_type":"code","source":"df_trn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e52a658cfca59135a496e06224e0f4c6ed2a4de"},"cell_type":"code","source":"df_trn.info(memory_usage='deep', verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d43ccdc9ca93fc1b4ff7e4d6a222a50e39577b6e"},"cell_type":"code","source":"df_tst.info(memory_usage='deep', verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29864b46f0d8fd733b14d2ed2e7809ff9137f0a3"},"cell_type":"markdown","source":"- The training dataset has 4.3M entries, which is not small and aloows for advanced models like GBM and NN to dominate.\n- The test dataset is only 1.9M entries\n- There are 25 features (+ the target in the train dataset)"},{"metadata":{"_uuid":"a71f070ac1c448815c6b8f0d78c4ee59bf66e6ab"},"cell_type":"markdown","source":"## Are there missing data?"},{"metadata":{"trusted":true,"_uuid":"de3b9626998858f27d05ce97f88b9a20a600b898"},"cell_type":"code","source":"df_trn.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7b2fb0b61e94c6d150fc07cf9410cd1e80bc873"},"cell_type":"markdown","source":"Good news: **There are no entries with `np.nan`**, so at the first glance we do not need to do anything fancy about missing data. \n\nThere might be some default values pre-filled into missing entries- this would have to be discovered."},{"metadata":{"_uuid":"8f85aa4008394e7dcf4efa4f429287807acfb1fa"},"cell_type":"markdown","source":"# Feature engineering to come here... [tba]"},{"metadata":{"_uuid":"56576460176b2f621f29292cb8071670a2bd429e"},"cell_type":"markdown","source":"# Prepare the data"},{"metadata":{"trusted":true,"_uuid":"012046b5bdad17115946f10f4cf60433a40b4209"},"cell_type":"code","source":"y = df_trn['winPlacePerc']\ndf_trn.drop('winPlacePerc', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93ab6b410268847ee9a143a26f5d548da736e6a8"},"cell_type":"markdown","source":"We will **NOT** use `Id, groupId, matchId`. The first one is a unique identifier and can be useful only in the case of data leakage. The other two would be useful in feature engineering with grouped stats per match and per team."},{"metadata":{"trusted":true,"_uuid":"4b82e48aa2338805b3874cee682bf2fe886e8ee6"},"cell_type":"code","source":"# we will NOT use \nfeatures_not2use = ['Id', 'groupId', 'matchId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a4a1abd568ab70b165add1b95704b76f0c2f98e"},"cell_type":"code","source":"for df in [df_trn, df_tst]:\n    df.drop(features_not2use, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8fe98adce4e5114c26cee619431260f57aa0c44"},"cell_type":"markdown","source":"# Train and evaluate a model\nStart by defining handy helper functions..."},{"metadata":{"trusted":true,"_uuid":"470b2148601eed76036363bac7028145954aae10","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.base import clone, ClassifierMixin, RegressorMixin\nimport lightgbm as lgb\n\n\ndef learning_rate_decay_power(current_iter):\n    '''\n    The function defines learning rate deay for LGBM\n    '''\n    base_learning_rate = 0.10\n    min_lr = 5e-2\n    lr = base_learning_rate  * np.power(.996, current_iter)\n    return lr if lr > min_lr else min_lr\n\n\ndef train_single_model(clf_, X_, y_, random_state_=314, opt_parameters_={}, fit_params_={}):\n    '''\n    A wrapper to train a model with particular parameters\n    '''\n    c = clone(clf_)\n    c.set_params(**opt_parameters_)\n    c.set_params(random_state=random_state_)\n    return c.fit(X_, y_, **fit_params_)\n\ndef train_model_in_CV(model, X, y, metric, metric_args={},\n                            model_name='xmodel',\n                            seed=31416, n=5,\n                            opt_parameters_={}, fit_params_={},\n                            verbose=True):\n    # the list of classifiers for voting ensable\n    clfs = []\n    # performance \n    perf_eval = {'score_i_oof': 0,\n                 'score_i_ave': 0,\n                 'score_i_std': 0,\n                 'score_i': []\n                }\n    # full-sample oof prediction\n    y_full_oof = pd.Series(np.zeros(shape=(y.shape[0],)), \n                          index=y.index)\n    \n    if 'sample_weight' in metric_args:\n        sample_weight=metric_args['sample_weight']\n        \n    doSqrt=False\n    if 'sqrt' in metric_args:\n        doSqrt=True\n        del metric_args['sqrt']\n\n    cv = KFold(n, shuffle=True, random_state=seed) #Stratified\n    # The out-of-fold (oof) prediction for the k-1 sample in the outer CV loop\n    y_oof = pd.Series(np.zeros(shape=(X.shape[0],)), \n                      index=X.index)\n    scores = []\n    clfs = []\n\n    for n_fold, (trn_idx, val_idx) in enumerate(cv.split(X, (y!=0).astype(np.int8))):\n        X_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n\n        if fit_params_:\n            # use _stp data for early stopping\n            fit_params_[\"eval_set\"] = [(X_trn,y_trn), (X_val,y_val)]\n            fit_params_['verbose'] = verbose\n\n        clf = train_single_model(model, X_trn, y_trn, 314+n_fold, opt_parameters_, fit_params_)\n\n        clfs.append(('{}{}'.format(model_name,n_fold), clf))\n        # evaluate performance\n        if isinstance(clf, RegressorMixin):\n            y_oof.iloc[val_idx] = clf.predict(X_val)\n        elif isinstance(clf, ClassifierMixin):\n            y_oof.iloc[val_idx] = clf.predict_proba(X_val)[:,1]\n        else:\n            raise TypeError('Provided model does not inherit neither from a regressor nor from classifier')\n        if 'sample_weight' in metric_args:\n            metric_args['sample_weight'] = y_val.map(sample_weight)\n        scores.append(metric(y_val, y_oof.iloc[val_idx], **metric_args))\n        #cleanup\n        del X_trn, y_trn, X_val, y_val\n\n    # Store performance info for this CV\n    if 'sample_weight' in metric_args:\n        metric_args['sample_weight'] = y_oof.map(sample_weight)\n    perf_eval['score_i_oof'] = metric(y, y_oof, **metric_args)\n    perf_eval['score_i'] = scores\n    \n    if doSqrt:\n        for k in perf_eval.keys():\n            if 'score' in k:\n                perf_eval[k] = np.sqrt(perf_eval[k])\n        scores = np.sqrt(scores)\n            \n    perf_eval['score_i_ave'] = np.mean(scores)\n    perf_eval['score_i_std'] = np.std(scores)\n\n    return clfs, perf_eval, y_oof\n\ndef print_perf_clf(name, perf_eval):\n    print('Performance of the model:')    \n    print('Mean(Val) score inner {} Classifier: {:.4f}+-{:.4f}'.format(name, \n                                                                      perf_eval['score_i_ave'],\n                                                                      perf_eval['score_i_std']\n                                                                     ))\n    print('Min/max scores on folds: {:.4f} / {:.4f}'.format(np.min(perf_eval['score_i']),\n                                                            np.max(perf_eval['score_i'])))\n    print('OOF score inner {} Classifier: {:.4f}'.format(name, perf_eval['score_i_oof']))\n    print('Scores in individual folds: {}'.format(perf_eval['score_i']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1782953ec79baf2bda4834c9c05085775cae3c4"},"cell_type":"markdown","source":"Now let's define the parameter and model in a scalable fashion (we can add later on further models to the list and it will work out-of-the-box). \n\nThe format is a dictionary with keys that are user model names and items being an array (or tuple) of:\n\n- model to be fitted;\n- additional model parameters to be set;\n- model fit parameters (they are passed to `model.fit()` call);\n- target variable."},{"metadata":{"trusted":true,"_uuid":"1ddb35cbc026b22ed8f9d7c7c11897f2a2636db9","_kg_hide-input":true},"cell_type":"code","source":"mdl_inputs = {\n        # This will be with MAE loss\n            'lgbm1_reg': (lgb.LGBMRegressor(max_depth=-1, min_child_samples=400, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, learning_rate=0.05),\n                 {'objective': 'mae', 'colsample_bytree': 0.75, 'min_child_weight': 10.0, 'num_leaves': 30, 'reg_alpha': 1, 'subsample': 0.75}, \n                 {\"early_stopping_rounds\":100, \n                  \"eval_metric\" : 'mae',\n                  'eval_names': ['train', 'early_stop'],\n                  'verbose': False, \n                  'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_decay_power)],\n                  'categorical_feature': 'auto'},\n                 y\n                ),\n#         'lgbm45_reg': (lgb.LGBMRegressor(max_depth=-1, min_child_samples=400, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, learning_rate=0.05),\n#                  {'objective': 'mae', 'colsample_bytree': 0.75, 'min_child_weight': 10.0, 'num_leaves': 45, 'reg_alpha': 1, 'subsample': 0.75}, \n#                  {\"early_stopping_rounds\":100, \n#                   \"eval_metric\" : 'mae',\n#                   'eval_names': ['train', 'early_stop'],\n#                   'verbose': False, \n#                   'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_decay_power)],\n#                   'categorical_feature': 'auto'},\n#                  y\n#                 ),\n#         'lgbm60_reg': (lgb.LGBMRegressor(max_depth=-1, min_child_samples=400, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, learning_rate=0.05),\n#                  {'objective': 'mae', 'colsample_bytree': 0.75, 'min_child_weight': 10.0, 'num_leaves': 60, 'reg_alpha': 1, 'subsample': 0.75}, \n#                  {\"early_stopping_rounds\":100, \n#                   \"eval_metric\" : 'mae',\n#                   'eval_names': ['train', 'early_stop'],\n#                   'verbose': False, \n#                   'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_decay_power)],\n#                   'categorical_feature': 'auto'},\n#                  y\n#                 ),\n#         'lgbm90_reg': (lgb.LGBMRegressor(max_depth=-1, min_child_samples=400, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, learning_rate=0.05),\n#                  {'objective': 'mae', 'colsample_bytree': 0.75, 'min_child_weight': 10.0, 'num_leaves': 90, 'reg_alpha': 1, 'subsample': 0.75}, \n#                  {\"early_stopping_rounds\":100, \n#                   \"eval_metric\" : 'mae',\n#                   'eval_names': ['train', 'early_stop'],\n#                   'verbose': False, \n#                   'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_decay_power)],\n#                   'categorical_feature': 'auto'},\n#                  y\n#                 ),\n        # This will be with FAIR loss\n#         'lgbm2_reg': (lgb.LGBMRegressor(max_depth=-1, min_child_samples=400, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, learning_rate=0.05),\n#                  {'objective': 'fair', 'colsample_bytree': 0.75, 'min_child_weight': 10.0, 'num_leaves': 30, 'reg_alpha': 1, 'subsample': 0.75}, \n#                  {\"early_stopping_rounds\":100, \n#                   \"eval_metric\" : 'mae',\n#                   'eval_names': ['train', 'early_stop'],\n#                   'verbose': False, \n#                   'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_decay_power)],\n#                   'categorical_feature': 'auto'},\n#                  y\n#                 ),\n       }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb04c3bfac89f557e3c8efdcced2677bf50bd583"},"cell_type":"markdown","source":"Do the actual model training"},{"metadata":{"trusted":true,"_uuid":"36302d78799176cf736aa3e4b81dfe36210cfb0f"},"cell_type":"code","source":"%%time\nmdls = {}\nresults = {}\ny_oofs = {}\nfor name, (mdl, mdl_pars, fit_pars, y_) in mdl_inputs.items():\n    print('--------------- {} -----------'.format(name))\n    mdl_, perf_eval_, y_oof_ = train_model_in_CV(mdl, df_trn, y_, mean_absolute_error, \n                                                          metric_args={},\n                                                          model_name=name, \n                                                          opt_parameters_=mdl_pars,\n                                                          fit_params_=fit_pars, \n                                                          n=n_cv,\n                                                          verbose=False)\n    results[name] = perf_eval_\n    mdls[name] = mdl_\n    y_oofs[name] = y_oof_\n    print_perf_clf(name, perf_eval_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36901d783546db24e3a21673b33a7ca9b293623c"},"cell_type":"markdown","source":"Let's plot how predictions look like"},{"metadata":{"trusted":true,"_uuid":"87ceda22c49754e4cbc15ff53055360dbd49e2ff"},"cell_type":"code","source":"k = list(y_oofs.keys())[0]\n_ = y_oofs[k].plot('hist', bins=100, figsize=(15,6))\nplt.xlabel('Predicted winPlacePerc OOF')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"804be78620382885375e8c3a23a656614e3d545e"},"cell_type":"markdown","source":"Note, that predictions are spilled outside of the `[0,1]` range, which is not meaningful for percentage value. **We will clip test predictions to be within the meaningful range.** This will improve the score slightly"},{"metadata":{"_uuid":"3bd60837ec18d8a3037015befd4f3a0bc44f6b19"},"cell_type":"markdown","source":"## Visualise importance of features"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"426b0274b32a45f5fbdc08884d81bf04b926e807"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef display_importances(feature_importance_df_, n_feat=30, silent=False, dump_strs=[], \n                        fout_name=None, title='Features (avg over folds)'):\n    '''\n    Make a plot of most important features from a tree-based model\n\n    Parameters\n    ----------\n    feature_importance_df_ : pd.DataFrame\n        The input dataframe. \n        Must contain columns `'feature'` and `'importance'`.\n        The dataframe will be first grouped by `'feature'` and the mean `'importance'` will be calculated.\n        This allows to calculate and plot importance averaged over folds, \n        when the same features appear in the dataframe as many time as there are folds in CV.\n    n_feats : int [default: 20]\n        The maximum number of the top features to be plotted\n    silent : bool [default: False]\n        Dump additionsl information, in particular the mean importances for features \n        defined by `dump_strs` and the features with zero (<1e-3) importance\n    dump_strs : list of strings [default: []]\n        Features containing either of these srings will be printed to the screen\n    fout_name : str or None [default: None]\n        The name of the file to dump the figure. \n        If `None`, no file is created (to be used in notebooks)\n    '''\n    # Plot feature importances\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n            by=\"importance\", ascending=False)[:n_feat].index  \n    \n    mean_imp = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n    df_2_neglect = mean_imp[mean_imp['importance'] < 1e-3]\n    \n    if not silent:\n        print('The list of features with 0 importance: ')\n        print(df_2_neglect.index.values.tolist())\n\n        pd.set_option('display.max_rows', 500)\n        pd.set_option('display.max_columns', 500)\n        for feat_prefix in dump_strs:\n            feat_names = [x for x in mean_imp.index if feat_prefix in x]\n            print(mean_imp.loc[feat_names].sort_values(by='importance', ascending=False))\n    del mean_imp, df_2_neglect\n    \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    \n    plt.figure(figsize=(8,10))\n    sns.barplot(x=\"importance\", y=\"feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title(title)\n    plt.tight_layout()\n\n    if fout_name is not None:\n        plt.savefig(fout_name)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1c0d180ec81be2dcfa875c0854e3e4249aeecd8"},"cell_type":"code","source":"display_importances(pd.DataFrame({'feature': df_trn.columns,\n                                  'importance': mdls['lgbm1_reg'][0][1].booster_.feature_importance('gain')}),\n                    n_feat=20,\n                    title='GAIN feature importance',\n                    fout_name='feature_importance_gain.png'\n                   )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c77dec7b90de56503e3af494fbfc6f55ab4e4f6"},"cell_type":"markdown","source":"## Prepare submission"},{"metadata":{"trusted":true,"_uuid":"7bd73f0231f934fc9fc49b25f8b54a8f819e6992"},"cell_type":"code","source":"%%time\ny_subs= {}\nfor c in mdl_inputs:\n    mdls_= mdls[c]\n    y_sub = np.zeros(df_tst.shape[0])\n    for mdl_ in mdls_:\n        y_sub += np.clip(mdl_[1].predict(df_tst), 0, 1)\n    y_sub /= n_cv\n    \n    y_subs[c] = y_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07bbca401b3481ab1bf8a634a62e872caa1044d3"},"cell_type":"code","source":"df_sub = pd.read_csv('../input/sample_submission.csv', nrows=max_events_tst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6231e9a078c84f9037b507105d8009c5d51e9b"},"cell_type":"code","source":"for c in mdl_inputs:\n    df_sub['winPlacePerc'] = y_subs[c]\n    df_sub.to_csv('sub_{}.csv'.format(c), index=False)\n    \n    oof = pd.DataFrame(y_oofs[c].values)\n    oof.columns = ['winPlacePerc']\n    oof.clip(0, 1, inplace=True)\n    oof.to_csv('oof_{}.csv'.format(c), index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb07a6de4adfcd57badea38b85ebcf7b3a2afa62"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0971f290973f1466a5d46522206160d0037f886e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}