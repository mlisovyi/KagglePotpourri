{"cells":[{"metadata":{"_uuid":"0e954899938f74715da7224308547332d6ac6b83"},"cell_type":"markdown","source":"# Hyper parameters\nThe goal here is to demonstrate how to optimise hyper-parameters of various models\n\nThe kernel is a short version of https://www.kaggle.com/mlisovyi/featureengineering-basic-model"},{"metadata":{"_uuid":"363c4db87adf90eae3efd54a999447350d0c0d1c","trusted":true},"cell_type":"code","source":"max_events = None","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D # needed for 3D scatter plots\n%matplotlib inline \nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nPATH='../input/'\n\nimport os\nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5196b4289e9964f7ecaf0f1920a7f2fe927dd0b5"},"cell_type":"markdown","source":"Read in data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('{}/train.csv'.format(PATH), nrows=max_events)\ntest  = pd.read_csv('{}/test.csv'.format(PATH), nrows=max_events)\n\ny = train['Cover_Type']\ntrain.drop('Cover_Type', axis=1, inplace=True)\n\ntrain.drop('Id', axis=1, inplace=True)\ntest.drop('Id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2575bf209deaa003b39e43c95c51e907dd2953a7","trusted":false},"cell_type":"code","source":"print('Train shape: {}'.format(train.shape))\nprint('Test  shape: {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbee752f879ab4ace9c89797d29672f65363ca13","trusted":false},"cell_type":"code","source":"train.info(verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f88d707436d0d80295e92c75bd63470e5726fd1a"},"cell_type":"markdown","source":"## OHE into LE"},{"metadata":{"_uuid":"aef656370958ac53e23a69b7f9f3bcc1b035054e"},"cell_type":"markdown","source":"Helper function to transfer One-Hot Encoding (OHE) into a Label Encoding (LE). It was taken from https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro\n\nThe reason to convert OHE into LE is that we plan to use a tree-based model and such models are dealing well with simple interger-label encoding. Note, that this way we introduce an ordering between categories, which is not there in reality, but in practice in most use cases GBMs handle it well anyway."},{"metadata":{"_kg_hide-input":true,"_uuid":"81784b6b486bf214090eb6fbed09c88c465fdb6a","trusted":false},"cell_type":"code","source":"def convert_OHE2LE(df):\n    tmp_df = df.copy(deep=True)\n    for s_ in ['Soil_Type', 'Wilderness_Area']:\n        cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n        #deal with those OHE, where there is a sum over columns == 0\n        if 0 in sum_ohe:\n            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n                  .format(s_))\n            # dummy colmn name to be added\n            col_dummy = s_+'_dummy'\n            # add the column to the dataframe\n            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n            # add the name to the list of columns to be label-encoded\n            cols_s_.append(col_dummy)\n            # proof-check, that now the category is complete\n            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n            if 0 in sum_ohe:\n                 print(\"The category completion did not work\")\n        tmp_df[s_ + '_LE'] = tmp_df[cols_s_].idxmax(axis=1).str.replace(s_,'').astype(np.uint16)\n        tmp_df.drop(cols_s_, axis=1, inplace=True)\n    return tmp_df\n\n\n\ndef train_test_apply_func(train_, test_, func_):\n    xx = pd.concat([train_, test_])\n    xx_func = func_(xx)\n    train_ = xx_func.iloc[:train_.shape[0], :]\n    test_  = xx_func.iloc[train_.shape[0]:, :]\n\n    del xx, xx_func\n    return train_, test_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3b296532fc774332272c125301edc78764401ff","trusted":false},"cell_type":"code","source":"train_x, test_x = train_test_apply_func(train, test, convert_OHE2LE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5ed710b9f1715c98af4ff18d7a9b106081830b6"},"cell_type":"markdown","source":"One little caveat: looking through the OHE, `Soil_Type 7, 15`, are present in the test, but not in the training data"},{"metadata":{"_uuid":"2186f6b4d38681d35139c5f044c4198c5cb45dec"},"cell_type":"markdown","source":"The head of the training dataset"},{"metadata":{"_uuid":"fdc8e01240a6ecfe910f36d3835452c5e09904ab","trusted":false},"cell_type":"code","source":"train_x.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aed67336822ef1348f33ba4080c92056375ae994"},"cell_type":"markdown","source":"# Let's do some feature engineering"},{"metadata":{"_uuid":"941935f4e9e5eed0c25211f481ffc0bdc5f99cdf","trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"def preprocess(df_):\n    df_['fe_E_Min_02HDtH'] = (df_['Elevation']- df_['Horizontal_Distance_To_Hydrology']*0.2).astype(np.float32)\n    df_['fe_Distance_To_Hydrology'] = np.sqrt(df_['Horizontal_Distance_To_Hydrology']**2 + \n                                              df_['Vertical_Distance_To_Hydrology']**2).astype(np.float32)\n    \n    feats_sub = [('Elevation_Min_VDtH', 'Elevation', 'Vertical_Distance_To_Hydrology'),\n                 ('HD_Hydrology_Min_Roadways', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways'),\n                 ('HD_Hydrology_Min_Fire', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points')]\n    feats_add = [('Elevation_Add_VDtH', 'Elevation', 'Vertical_Distance_To_Hydrology')]\n    \n    for f_new, f1, f2 in feats_sub:\n        df_['fe_' + f_new] = (df_[f1] - df_[f2]).astype(np.float32)\n    for f_new, f1, f2 in feats_add:\n        df_['fe_' + f_new] = (df_[f1] + df_[f2]).astype(np.float32)\n        \n    # The feature is advertised in https://douglas-fraser.com/forest_cover_management.pdf\n    df_['fe_Shade9_Mul_VDtH'] = (df_['Hillshade_9am'] * df_['Vertical_Distance_To_Hydrology']).astype(np.float32)\n    \n    # this mapping comes from https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info\n    climatic_zone = {}\n    geologic_zone = {}\n    for i in range(1,41):\n        if i <= 6:\n            climatic_zone[i] = 2\n            geologic_zone[i] = 7\n        elif i <= 8:\n            climatic_zone[i] = 3\n            geologic_zone[i] = 5\n        elif i == 9:\n            climatic_zone[i] = 4\n            geologic_zone[i] = 2\n        elif i <= 13:\n            climatic_zone[i] = 4\n            geologic_zone[i] = 7\n        elif i <= 15:\n            climatic_zone[i] = 5\n            geologic_zone[i] = 1\n        elif i <= 17:\n            climatic_zone[i] = 6\n            geologic_zone[i] = 1\n        elif i == 18:\n            climatic_zone[i] = 6\n            geologic_zone[i] = 7\n        elif i <= 21:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 1\n        elif i <= 23:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 2\n        elif i <= 34:\n            climatic_zone[i] = 7\n            geologic_zone[i] = 7\n        else:\n            climatic_zone[i] = 8\n            geologic_zone[i] = 7\n            \n    df_['Climatic_zone_LE'] = df_['Soil_Type_LE'].map(climatic_zone).astype(np.uint8)\n    df_['Geologic_zone_LE'] = df_['Soil_Type_LE'].map(geologic_zone).astype(np.uint8)\n    return df_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42c3309fcabc6b481984a2e03509b383698392af","trusted":false},"cell_type":"code","source":"train_x = preprocess(train_x)\ntest_x = preprocess(test_x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0d4e6071e23750d7804db00fb83316651f87ffb"},"cell_type":"markdown","source":"# Optimise various classifiers"},{"metadata":{"_uuid":"03b46c6db6ce788be24e9ecba73afd15362beed9","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom  sklearn.linear_model import LogisticRegression\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7dcd6025c5dbe9e5939216aee314616118cd468"},"cell_type":"markdown","source":"We subtract 1 to have the labels starting with 0, which is required for LightGBM"},{"metadata":{"trusted":false,"_uuid":"5c712a0b7adb411215207ef4c126934efa40fb85"},"cell_type":"code","source":"y = y-1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1d406d0588bf959c4c76e1057db1acfbe576188","trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_x, y, test_size=0.15, random_state=315, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f70a26910d98ae13d7fe71ad6584d34533163075"},"cell_type":"markdown","source":"Parameters to be used in optimisation for various models"},{"metadata":{"_uuid":"0a97420c99db2876bcd3af3966fcc0357cda9d46","trusted":false},"cell_type":"code","source":"def learning_rate_decay_power_0995(current_iter):\n    base_learning_rate = 0.15\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-2 else 1e-2\n\nclfs = {'rf': (RandomForestClassifier(n_estimators=200, max_depth=1, random_state=314, n_jobs=4),\n               {'max_depth': [20,25,30,35,40,45,50]}, \n               {}),\n        'xt': (ExtraTreesClassifier(n_estimators=200, max_depth=1, max_features='auto',random_state=314, n_jobs=4),\n               {'max_depth': [20,25,30,35,40,45,50]},\n               {}),\n        'lgbm': (lgb.LGBMClassifier(max_depth=-1, min_child_samples=400, \n                                 random_state=314, silent=True, metric='None', \n                                 n_jobs=4, n_estimators=5000, learning_rate=0.1), \n                 {'colsample_bytree': [0.75], 'min_child_weight': [0.1,1,10], 'num_leaves': [18, 20,22], 'subsample': [0.75]}, \n                 {'eval_set': [(X_test, y_test)], \n                  'eval_metric': 'multi_error', 'verbose':500, 'early_stopping_rounds':100, \n                  'callbacks':[lgb.reset_parameter(learning_rate=learning_rate_decay_power_0995)]}\n                )\n       }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ba7fa403dabfbfb7f340922fd20ec5dcc008d59","trusted":false},"cell_type":"code","source":"gss = {}\nfor name, (clf, clf_pars, fit_pars) in clfs.items():\n    print('--------------- {} -----------'.format(name))\n    gs = GridSearchCV(clf, param_grid=clf_pars,\n                            scoring='accuracy',\n                            cv=5,\n                            n_jobs=1,\n                            refit=True,\n                            verbose=True)\n    gs = gs.fit(X_train, y_train, **fit_pars)\n    print('{}:  train = {:.4f}, test = {:.4f}+-{:.4f} with best params {}'.format(name, \n                                                                                  gs.cv_results_['mean_train_score'][gs.best_index_],\n                                                                                  gs.cv_results_['mean_test_score'][gs.best_index_],\n                                                                                  gs.cv_results_['std_test_score'][gs.best_index_],\n                                                                                  gs.best_params_\n                                                                                 ))\n    print(\"Valid+-Std     Train  :   Parameters\")\n    for i in np.argsort(gs.cv_results_['mean_test_score'])[-5:]:\n        print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs.cv_results_['params'][i], \n                                        gs.cv_results_['mean_test_score'][i], \n                                        gs.cv_results_['mean_train_score'][i],\n                                        gs.cv_results_['std_test_score'][i]))\n    gss[name] = gs","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bd406202a0b03418907cf4c9d0b4f2eb4e6d0776","_kg_hide-input":true},"cell_type":"code","source":"# gss = {}\n# for name, (clf, clf_pars, fit_pars) in clfs.items():\n#     if name == 'lgbm':\n#         continue\n#     print('--------------- {} -----------'.format(name))\n#     gs = GridSearchCV(clf, param_grid=clf_pars,\n#                             scoring='accuracy',\n#                             cv=5,\n#                             n_jobs=1,\n#                             refit=True,\n#                             verbose=True)\n#     gs = gs.fit(X_train, y_train, **fit_pars)\n#     print('{}:  train = {:.4f}, test = {:.4f}+-{:.4f} with best params {}'.format(name, \n#                                                                                   gs.cv_results_['mean_train_score'][gs.best_index_],\n#                                                                                   gs.cv_results_['mean_test_score'][gs.best_index_],\n#                                                                                   gs.cv_results_['std_test_score'][gs.best_index_],\n#                                                                                   gs.best_params_\n#                                                                                  ))\n#     print(\"Valid+-Std     Train  :   Parameters\")\n#     for i in np.argsort(gs.cv_results_['mean_test_score'])[-5:]:\n#         print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs.cv_results_['params'][i], \n#                                         gs.cv_results_['mean_test_score'][i], \n#                                         gs.cv_results_['mean_train_score'][i],\n#                                         gs.cv_results_['std_test_score'][i]))\n#     gss[name] = gs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"795ea36b14dfeb796eb205919ed51d0a2c8086ff"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}